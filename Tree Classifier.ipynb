{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Tree Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting data into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "noClauses = [300,500,1000,1500,1800]\n",
    "noSamples = [100,1000,5000]\n",
    "\n",
    "trainSampleNames = []\n",
    "trainData = {}\n",
    "\n",
    "validationSampleNames = []\n",
    "validationData = {}\n",
    "\n",
    "testSampleNames = []\n",
    "testData = {}\n",
    "\n",
    "for i in range (len(noClauses)):\n",
    "    for j in range (len(noSamples)):\n",
    "        tempName = \"train_c\"+str(noClauses[i])+\"_d\"+str(noSamples[j])\n",
    "        trainSampleNames.append(tempName)\n",
    "        trainData[tempName] = pd.read_csv(\"hw3_part1_data/all_data/\"+tempName+\".csv\",sep=\",\",header=None)\n",
    "\n",
    "        tempName = \"test_c\"+str(noClauses[i])+\"_d\"+str(noSamples[j])\n",
    "        testSampleNames.append(tempName)\n",
    "        testData[tempName] = pd.read_csv(\"hw3_part1_data/all_data/\"+tempName+\".csv\",sep=\",\",header=None)\n",
    "\n",
    "        tempName = \"valid_c\"+str(noClauses[i])+\"_d\"+str(noSamples[j])\n",
    "        validationSampleNames.append(tempName)\n",
    "        validationData[tempName] = pd.read_csv(\"hw3_part1_data/all_data/\"+tempName+\".csv\",sep=\",\",header=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the validation set to tune the parameters.\n",
    "#### We will be using the predefined split package to use Training data to train the model and use the validation set to validate and tune the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -  train_c300_d100\n",
      "Best Score achieved : 0.6650\n",
      "Parameters that give the best results :  {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 20}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60       100\n",
      "           1       0.61      0.67      0.64       100\n",
      "\n",
      "    accuracy                           0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "Training -  train_c300_d1000\n",
      "Best Score achieved : 0.6520\n",
      "Parameters that give the best results :  {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.55      0.62      1000\n",
      "           1       0.64      0.80      0.71      1000\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.68      0.67      0.67      2000\n",
      "weighted avg       0.68      0.67      0.67      2000\n",
      "\n",
      "Training -  train_c300_d5000\n",
      "Best Score achieved : 0.7468\n",
      "Parameters that give the best results :  {'criterion': 'entropy', 'max_depth': 9, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 30}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.72      0.77      5000\n",
      "           1       0.75      0.86      0.80      5000\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.78     10000\n",
      "weighted avg       0.79      0.79      0.78     10000\n",
      "\n",
      "Training -  train_c500_d100\n",
      "Best Score achieved : 0.6700\n",
      "Parameters that give the best results :  {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72       100\n",
      "           1       0.74      0.64      0.68       100\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.71      0.71      0.70       200\n",
      "weighted avg       0.71      0.70      0.70       200\n",
      "\n",
      "Training -  train_c500_d1000\n",
      "Best Score achieved : 0.7050\n",
      "Parameters that give the best results :  {'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 50}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74      1000\n",
      "           1       0.76      0.65      0.70      1000\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.73      0.72      0.72      2000\n",
      "weighted avg       0.73      0.72      0.72      2000\n",
      "\n",
      "Training -  train_c500_d5000\n",
      "Best Score achieved : 0.7704\n",
      "Parameters that give the best results :  {'criterion': 'entropy', 'max_depth': 9, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 30}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78      5000\n",
      "           1       0.76      0.85      0.80      5000\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n",
      "Training -  train_c1000_d100\n",
      "Best Score achieved : 0.7650\n",
      "Parameters that give the best results :  {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71       100\n",
      "           1       0.71      0.72      0.71       100\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.71      0.71      0.71       200\n",
      "weighted avg       0.71      0.71      0.71       200\n",
      "\n",
      "Training -  train_c1000_d1000\n",
      "Best Score achieved : 0.8020\n",
      "Parameters that give the best results :  {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79      1000\n",
      "           1       0.77      0.86      0.81      1000\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.80      0.80      0.80      2000\n",
      "weighted avg       0.80      0.80      0.80      2000\n",
      "\n",
      "Training -  train_c1000_d5000\n",
      "Best Score achieved : 0.8426\n",
      "Parameters that give the best results :  {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 50}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      5000\n",
      "           1       0.84      0.87      0.86      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "Training -  train_c1500_d100\n",
      "Best Score achieved : 0.8700\n",
      "Parameters that give the best results :  {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88       100\n",
      "           1       0.85      0.94      0.89       100\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.89      0.89      0.88       200\n",
      "weighted avg       0.89      0.89      0.88       200\n",
      "\n",
      "Training -  train_c1500_d1000\n",
      "Best Score achieved : 0.9220\n",
      "Parameters that give the best results :  {'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      1000\n",
      "           1       0.92      0.93      0.92      1000\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.92      0.92      0.92      2000\n",
      "weighted avg       0.92      0.92      0.92      2000\n",
      "\n",
      "Training -  train_c1500_d5000\n",
      "Best Score achieved : 0.9469\n",
      "Parameters that give the best results :  {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      5000\n",
      "           1       0.95      0.96      0.96      5000\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Training -  train_c1800_d100\n",
      "Best Score achieved : 0.9800\n",
      "Parameters that give the best results :  {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       100\n",
      "           1       0.95      0.93      0.94       100\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.94      0.94       200\n",
      "weighted avg       0.94      0.94      0.94       200\n",
      "\n",
      "Training -  train_c1800_d1000\n",
      "Best Score achieved : 0.9695\n",
      "Parameters that give the best results :  {'criterion': 'entropy', 'max_depth': 9, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.96      0.98      0.97      1000\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n",
      "Training -  train_c1800_d5000\n",
      "Best Score achieved : 0.9872\n",
      "Parameters that give the best results :  {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5000\n",
      "           1       0.99      0.99      0.99      5000\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "grid = [{'criterion': ['gini', 'entropy'],\n",
    "         'max_depth': [2, 5, 9, None],\n",
    "         'min_samples_split': [2, 7, 10 , 20, 30, 50],\n",
    "         'min_samples_leaf': [1, 8, 15],\n",
    "         'max_features' : [5, 9 , None]\n",
    "         }]\n",
    "\n",
    "bestParameters = {}\n",
    "results = {}\n",
    "\n",
    "for i in trainSampleNames:\n",
    "    \n",
    "    # -1 - train\n",
    "    # 0 - validate\n",
    "    temp1 = np.full( (trainData[i]).shape[0] , -1 )\n",
    "    temp2 = np.full( ((validationData[validationSampleNames[trainSampleNames.index(i)]])).shape[0] , 0)\n",
    "\n",
    "    split_index =   np.concatenate((temp1, temp2), axis=0)\n",
    "    # print(split_index)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "\n",
    "    TrainDataset = (trainData[i]).append((validationData[validationSampleNames[trainSampleNames.index(i)]]) , ignore_index = True)\n",
    "    # print(TrainDataset)\n",
    "\n",
    "    print(\"Training - \", i)\n",
    "\n",
    "    GS = GridSearchCV(estimator = tree, param_grid = grid[0], scoring = 'accuracy', cv = pds)\n",
    "    GS.fit( TrainDataset.iloc[:,:500], TrainDataset.iloc[:,-1] )\n",
    "    print(\"Best Score achieved : {:.4f}\".format(GS.best_score_))\n",
    "    print(\"Parameters that give the best results : \",(GS.best_params_))\n",
    "    bestParameters[i] = GS.best_params_\n",
    "    \n",
    "    # Relearning using the best parameters found above to find the accuracy and F1 score on test dataset\n",
    "\n",
    "    testTree = DecisionTreeClassifier(criterion = (bestParameters[i])['criterion'] , max_depth= (bestParameters[i])['max_depth'], max_features= (bestParameters[i])['max_features'], min_samples_leaf= (bestParameters[i])['min_samples_leaf'], min_samples_split= (bestParameters[i])['min_samples_split'])\n",
    "    testTree.fit(TrainDataset.iloc[:,:500], TrainDataset.iloc[:,-1])\n",
    "    predictions = testTree.predict((testData[testSampleNames[trainSampleNames.index(i)]]).iloc[:,:500])\n",
    "    results[i] = classification_report( (testData[testSampleNames[trainSampleNames.index(i)]]).iloc[:,-1] , predictions)\n",
    "\n",
    "    print(\"resultsssss \\n\",results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -  train_c300_d100\n",
      "Best Score achieved : 0.7250\n",
      "Parameters that give the best results :  {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 40, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73       100\n",
      "           1       0.72      0.79      0.76       100\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.75      0.74      0.74       200\n",
      "weighted avg       0.75      0.74      0.74       200\n",
      "\n",
      "Training -  train_c300_d1000\n",
      "Best Score achieved : 0.8635\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 60, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      1000\n",
      "           1       0.86      0.89      0.87      1000\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.87      0.87      0.87      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n",
      "Training -  train_c300_d5000\n",
      "Best Score achieved : 0.9257\n",
      "Parameters that give the best results :  {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 60, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      5000\n",
      "           1       0.93      0.96      0.94      5000\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Training -  train_c500_d100\n",
      "Best Score achieved : 0.7700\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 60, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       100\n",
      "           1       0.84      0.87      0.86       100\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.86      0.85      0.85       200\n",
      "weighted avg       0.86      0.85      0.85       200\n",
      "\n",
      "Training -  train_c500_d1000\n",
      "Best Score achieved : 0.8930\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 60, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1000\n",
      "           1       0.91      0.91      0.91      1000\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.91      0.91      0.91      2000\n",
      "weighted avg       0.91      0.91      0.91      2000\n",
      "\n",
      "Training -  train_c500_d5000\n",
      "Best Score achieved : 0.9335\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 60, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      5000\n",
      "           1       0.95      0.96      0.95      5000\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Training -  train_c1000_d100\n",
      "Best Score achieved : 0.9200\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 60, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       100\n",
      "           1       0.94      0.90      0.92       100\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.92      0.92      0.92       200\n",
      "weighted avg       0.92      0.92      0.92       200\n",
      "\n",
      "Training -  train_c1000_d1000\n",
      "Best Score achieved : 0.9725\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 60, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1000\n",
      "           1       0.96      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n",
      "Training -  train_c1000_d5000\n",
      "Best Score achieved : 0.9792\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 60, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5000\n",
      "           1       0.99      0.99      0.99      5000\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "Training -  train_c1500_d100\n",
      "Best Score achieved : 0.9800\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 40, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       100\n",
      "           1       0.99      0.99      0.99       100\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       0.99      0.99      0.99       200\n",
      "weighted avg       0.99      0.99      0.99       200\n",
      "\n",
      "Training -  train_c1500_d1000\n",
      "Best Score achieved : 0.9955\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 60, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1000\n",
      "           1       0.99      0.99      0.99      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Training -  train_c1500_d5000\n",
      "Best Score achieved : 0.9968\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 40, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Training -  train_c1800_d100\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 60, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       100\n",
      "           1       0.99      0.98      0.98       100\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.99      0.98      0.98       200\n",
      "weighted avg       0.99      0.98      0.98       200\n",
      "\n",
      "Training -  train_c1800_d1000\n",
      "Best Score achieved : 0.9975\n",
      "Parameters that give the best results :  {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 60, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Training -  train_c1800_d5000\n",
      "Best Score achieved : 0.9992\n",
      "Parameters that give the best results :  {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 40, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier())\n",
    "grid = [{'n_estimators': [2, 40, 60],\n",
    "         'bootstrap': [True, False],\n",
    "         'bootstrap_features': [True, False],\n",
    "         'warm_start' : [True, False]\n",
    "         }]\n",
    "\n",
    "bestParametersBagging = {}\n",
    "resultsBagging = {}\n",
    "\n",
    "for i in trainSampleNames:\n",
    "    \n",
    "    # -1 - train\n",
    "    # 0 - validate\n",
    "    temp1 = np.full( (trainData[i]).shape[0] , -1 )\n",
    "    temp2 = np.full( ((validationData[validationSampleNames[trainSampleNames.index(i)]])).shape[0] , 0)\n",
    "\n",
    "    split_index =   np.concatenate((temp1, temp2), axis=0)\n",
    "    # print(split_index)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "\n",
    "    TrainDataset = (trainData[i]).append((validationData[validationSampleNames[trainSampleNames.index(i)]]) , ignore_index = True)\n",
    "    # print(TrainDataset)\n",
    "\n",
    "    print(\"Training - \", i)\n",
    "\n",
    "    gridSearchCv = GridSearchCV(estimator = BaggingClassifier(), param_grid = grid[0], scoring = 'accuracy', cv = pds)\n",
    "    # print(gridSearchCv)\n",
    "    gridSearchCv.fit( TrainDataset.iloc[:,:500], TrainDataset.iloc[:,-1] )\n",
    "    print(\"Best Score achieved : {:.4f}\".format(gridSearchCv.best_score_))\n",
    "    print(\"Parameters that give the best results : \",(gridSearchCv.best_params_))\n",
    "    bestParametersBagging[i] = gridSearchCv.best_params_\n",
    "    \n",
    "    # Relearning using the best parameters found above to find the accuracy and F1 score on test dataset\n",
    "\n",
    "    testBagging = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators= (bestParametersBagging[i])['n_estimators'], bootstrap= (bestParametersBagging[i])['bootstrap'], bootstrap_features= (bestParametersBagging[i])['bootstrap_features'] , warm_start = (bestParametersBagging[i])['warm_start'] )\n",
    "    testBagging.fit(TrainDataset.iloc[:,:500], TrainDataset.iloc[:,-1])\n",
    "    predictions = testBagging.predict((testData[testSampleNames[trainSampleNames.index(i)]]).iloc[:,:500])\n",
    "    resultsBagging[i] = classification_report( (testData[testSampleNames[trainSampleNames.index(i)]]).iloc[:,-1] , predictions)\n",
    "\n",
    "    print(\"resultsssss \\n\",resultsBagging[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -  train_c300_d100\n",
      "Best Score achieved : 0.8050\n",
      "Parameters that give the best results :  {'bootstrap': False, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 100, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       100\n",
      "           1       0.79      0.85      0.82       100\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.81      0.81       200\n",
      "weighted avg       0.81      0.81      0.81       200\n",
      "\n",
      "Training -  train_c300_d1000\n",
      "Best Score achieved : 0.8775\n",
      "Parameters that give the best results :  {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      1000\n",
      "           1       0.86      0.87      0.86      1000\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "Training -  train_c300_d5000\n",
      "Best Score achieved : 0.9201\n",
      "Parameters that give the best results :  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 20, 'n_estimators': 100, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      5000\n",
      "           1       0.92      0.94      0.93      5000\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Training -  train_c500_d100\n",
      "Best Score achieved : 0.9000\n",
      "Parameters that give the best results :  {'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 100, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       100\n",
      "           1       0.90      0.90      0.90       100\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.90      0.90       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n",
      "Training -  train_c500_d1000\n",
      "Best Score achieved : 0.9370\n",
      "Parameters that give the best results :  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1000\n",
      "           1       0.93      0.95      0.94      1000\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.94      0.94      0.94      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n",
      "Training -  train_c500_d5000\n",
      "Best Score achieved : 0.9522\n",
      "Parameters that give the best results :  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      5000\n",
      "           1       0.94      0.96      0.95      5000\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Training -  train_c1000_d100\n",
      "Best Score achieved : 0.9900\n",
      "Parameters that give the best results :  {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       100\n",
      "           1       0.99      0.97      0.98       100\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.98      0.98      0.98       200\n",
      "weighted avg       0.98      0.98      0.98       200\n",
      "\n",
      "Training -  train_c1000_d1000\n",
      "Best Score achieved : 0.9925\n",
      "Parameters that give the best results :  {'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1000\n",
      "           1       0.99      0.99      0.99      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Training -  train_c1000_d5000\n",
      "Best Score achieved : 0.9945\n",
      "Parameters that give the best results :  {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 100, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5000\n",
      "           1       0.99      0.99      0.99      5000\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "Training -  train_c1500_d100\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       100\n",
      "           1       0.99      1.00      1.00       100\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       1.00      0.99      0.99       200\n",
      "weighted avg       1.00      0.99      0.99       200\n",
      "\n",
      "Training -  train_c1500_d1000\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 50, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Training -  train_c1500_d5000\n",
      "Best Score achieved : 0.9999\n",
      "Parameters that give the best results :  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 50, 'warm_start': False}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Training -  train_c1800_d100\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "Training -  train_c1800_d1000\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Training -  train_c1800_d5000\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100, 'warm_start': True}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "randomForest = RandomForestClassifier()\n",
    "\n",
    "grid = [{'n_estimators' :[10, 50, 100],\n",
    "         'criterion': ['gini', 'entropy'],\n",
    "         'max_depth': [5, 10,  None],\n",
    "         'min_samples_split': [2, 10 , 20],\n",
    "         'bootstrap': [True, False],\n",
    "         'warm_start' : [True, False]\n",
    "         }]\n",
    "\n",
    "bestParametersrandomForest = {}\n",
    "resultsrandomForest = {}\n",
    "\n",
    "for i in trainSampleNames:\n",
    "    \n",
    "    # -1 - train\n",
    "    # 0 - validate\n",
    "    temp1 = np.full( (trainData[i]).shape[0] , -1 )\n",
    "    temp2 = np.full( ((validationData[validationSampleNames[trainSampleNames.index(i)]])).shape[0] , 0)\n",
    "\n",
    "    split_index =   np.concatenate((temp1, temp2), axis=0)\n",
    "    # print(split_index)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "\n",
    "    TrainDataset = (trainData[i]).append((validationData[validationSampleNames[trainSampleNames.index(i)]]) , ignore_index = True)\n",
    "    # print(TrainDataset)\n",
    "\n",
    "    print(\"Training - \", i)\n",
    "\n",
    "    gridSearchCv = GridSearchCV(estimator = RandomForestClassifier(), param_grid = grid[0], scoring = 'accuracy', cv = pds)\n",
    "    # print(gridSearchCv)\n",
    "    gridSearchCv.fit( TrainDataset.iloc[:,:500], TrainDataset.iloc[:,-1] )\n",
    "    print(\"Best Score achieved : {:.4f}\".format(gridSearchCv.best_score_))\n",
    "    print(\"Parameters that give the best results : \",(gridSearchCv.best_params_))\n",
    "    bestParametersrandomForest[i] = gridSearchCv.best_params_\n",
    "    \n",
    "    # Relearning using the best parameters found above to find the accuracy and F1 score on test dataset\n",
    "\n",
    "    testrandomForest = RandomForestClassifier(n_estimators= (bestParametersrandomForest[i])['n_estimators'], criterion= (bestParametersrandomForest[i])['criterion'], max_depth= (bestParametersrandomForest[i])['max_depth'], min_samples_split= (bestParametersrandomForest[i])['min_samples_split'] , bootstrap = (bestParametersrandomForest[i])['bootstrap'], warm_start = (bestParametersrandomForest[i])['warm_start'] )\n",
    "    testrandomForest.fit(TrainDataset.iloc[:,:500], TrainDataset.iloc[:,-1])\n",
    "    predictions = testrandomForest.predict((testData[testSampleNames[trainSampleNames.index(i)]]).iloc[:,:500])\n",
    "    resultsrandomForest[i] = classification_report( (testData[testSampleNames[trainSampleNames.index(i)]]).iloc[:,-1] , predictions)\n",
    "\n",
    "    print(\"resultsssss \\n\",resultsrandomForest[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -  train_c300_d100\n",
      "Best Score achieved : 0.7900\n",
      "Parameters that give the best results :  {'criterion': 'mse', 'learning_rate': 0.5, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       100\n",
      "           1       0.83      0.81      0.82       100\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.82      0.82      0.82       200\n",
      "weighted avg       0.82      0.82      0.82       200\n",
      "\n",
      "Training -  train_c300_d1000\n",
      "Best Score achieved : 0.8910\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 0.5, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      1000\n",
      "           1       0.86      0.87      0.86      1000\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "Training -  train_c300_d5000\n",
      "Best Score achieved : 0.9298\n",
      "Parameters that give the best results :  {'criterion': 'mse', 'learning_rate': 0.075, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      5000\n",
      "           1       0.92      0.95      0.94      5000\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Training -  train_c500_d100\n",
      "Best Score achieved : 0.9050\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 0.5, 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       100\n",
      "           1       0.89      0.89      0.89       100\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.89      0.89      0.89       200\n",
      "weighted avg       0.89      0.89      0.89       200\n",
      "\n",
      "Training -  train_c500_d1000\n",
      "Best Score achieved : 0.9465\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 0.5, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1000\n",
      "           1       0.95      0.95      0.95      1000\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.95      0.95      0.95      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n",
      "Training -  train_c500_d5000\n",
      "Best Score achieved : 0.9655\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 0.5, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      5000\n",
      "           1       0.96      0.98      0.97      5000\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "Training -  train_c1000_d100\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'criterion': 'mse', 'learning_rate': 1.0, 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       100\n",
      "           1       0.98      0.98      0.98       100\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.98      0.98      0.98       200\n",
      "weighted avg       0.98      0.98      0.98       200\n",
      "\n",
      "Training -  train_c1000_d1000\n",
      "Best Score achieved : 0.9980\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 0.075, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1000\n",
      "           1       0.99      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       1.00      0.99      0.99      2000\n",
      "weighted avg       1.00      0.99      0.99      2000\n",
      "\n",
      "Training -  train_c1000_d5000\n",
      "Best Score achieved : 0.9987\n",
      "Parameters that give the best results :  {'criterion': 'mse', 'learning_rate': 0.5, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Training -  train_c1500_d100\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 1.0, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "Training -  train_c1500_d1000\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 1.0, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Training -  train_c1500_d5000\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 1.0, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Training -  train_c1800_d100\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 1.0, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "Training -  train_c1800_d1000\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 1.0, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Training -  train_c1800_d5000\n",
      "Best Score achieved : 1.0000\n",
      "Parameters that give the best results :  {'criterion': 'friedman_mse', 'learning_rate': 1.0, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "resultsssss \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gradientBoosting = GradientBoostingClassifier()\n",
    "\n",
    "grid = [{'n_estimators' :[10, 50, 100],\n",
    "         'criterion': ['friedman_mse','mse'],\n",
    "         'max_depth': [3, 10,  None],\n",
    "         'min_samples_split': [2, 10 , 20],\n",
    "         'min_samples_leaf' : [1,5,0.5],\n",
    "         'max_features' : ['sqrt','log2'],\n",
    "         'learning_rate' : [1.0,0.075,0.5]\n",
    "         }]\n",
    "\n",
    "bestParametersgradientBoosting = {}\n",
    "resultsgradientBoosting = {}\n",
    "\n",
    "for i in trainSampleNames:\n",
    "    \n",
    "    # -1 - train\n",
    "    # 0 - validate\n",
    "    temp1 = np.full( (trainData[i]).shape[0] , -1 )\n",
    "    temp2 = np.full( ((validationData[validationSampleNames[trainSampleNames.index(i)]])).shape[0] , 0)\n",
    "\n",
    "    split_index =   np.concatenate((temp1, temp2), axis=0)\n",
    "    # print(split_index)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "\n",
    "    TrainDataset = (trainData[i]).append((validationData[validationSampleNames[trainSampleNames.index(i)]]) , ignore_index = True)\n",
    "    # print(TrainDataset)\n",
    "\n",
    "    print(\"Training - \", i)\n",
    "\n",
    "    gridSearchCv = GridSearchCV(GradientBoostingClassifier(), param_grid = grid[0], scoring = 'accuracy', cv = pds)\n",
    "    # print(gridSearchCv)\n",
    "    gridSearchCv.fit( TrainDataset.iloc[:,:500], TrainDataset.iloc[:,-1] )\n",
    "    print(\"Best Score achieved : {:.4f}\".format(gridSearchCv.best_score_))\n",
    "    print(\"Parameters that give the best results : \",(gridSearchCv.best_params_))\n",
    "    bestParametersgradientBoosting[i] = gridSearchCv.best_params_\n",
    "    \n",
    "    # Relearning using the best parameters found above to find the accuracy and F1 score on test dataset\n",
    "\n",
    "    testgradientBoosting = GradientBoostingClassifier(n_estimators= (bestParametersgradientBoosting[i])['n_estimators'], criterion= (bestParametersgradientBoosting[i])['criterion'], max_depth= (bestParametersgradientBoosting[i])['max_depth'], min_samples_split= (bestParametersgradientBoosting[i])['min_samples_split'] , min_samples_leaf = (bestParametersgradientBoosting[i])['min_samples_leaf'],max_features = (bestParametersgradientBoosting[i])['max_features'] )\n",
    "    testgradientBoosting.fit(TrainDataset.iloc[:,:500], TrainDataset.iloc[:,-1])\n",
    "    predictions = testgradientBoosting.predict((testData[testSampleNames[trainSampleNames.index(i)]]).iloc[:,:500])\n",
    "    resultsgradientBoosting[i] = classification_report( (testData[testSampleNames[trainSampleNames.index(i)]]).iloc[:,-1] , predictions)\n",
    "\n",
    "    print(\"resultsssss \\n\",resultsgradientBoosting[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "531b0134987c0aafae321ed1cd8f9e42c457322123fad9ee871b5aa55e2a1c2c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('hw1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
